{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349cdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caiman.source_extraction.cnmf import cnmf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import interpolate, stats\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "from src.datetime import add_frames_to_datetime, datetime_to_frame, image_desc_to_datetime, timestamp_to_datetime\n",
    "from src.tensor import min_max\n",
    "from src.tensor_creation_hyperparams import Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fe93d",
   "metadata": {},
   "source": [
    "## Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4957601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for F147\n",
    "F147 = Hyperparams(name='F147')\n",
    "F147.set_data_paths(estimates=[\n",
    "    'results/F147_0_memmap__d1_247_d2_256_d3_1_order_C_frames_20995_.hdf5',\n",
    "    'results/F147_1_memmap__d1_73_d2_256_d3_1_order_C_frames_20995_.hdf5'\n",
    "])\n",
    "F147.set_trial_metadata(\n",
    "    trial='data/2p_raw/F147/20210526_LT_18_0.mat',\n",
    "    trial_var='trial',\n",
    "    trial_time_field='timestamps',\n",
    "    trial_output_field='output',\n",
    "    trial_heat_onset_field='laseron',\n",
    "    trial_turn_field='turn_frame',\n",
    "    trial_fr=160\n",
    ")\n",
    "F147.set_image_metadata(\n",
    "    image='results/F147_imfinfo_edit.mat',\n",
    "    image_var='image',\n",
    "    image_time_field='ImageDescription',\n",
    "    image_fr=4.5\n",
    ")\n",
    "F147.set_component_evaluation(snr_thr=1.25, baseline_name='baseline', baseline_selected=1)\n",
    "F147.set_alignment_params(max_seconds_turn_to_end=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for F201\n",
    "F201 = Hyperparams(name='F201')\n",
    "F201.set_data_paths(estimates=[\n",
    "    'results/F201_0_memmap__d1_320_d2_256_d3_1_order_C_frames_24040_.hdf5'\n",
    "])\n",
    "F201.set_trial_metadata(\n",
    "    trial='data/2p_raw/F201/20210812_RT_13_59.mat',\n",
    "    trial_var='trial',\n",
    "    trial_time_field='timestamps',\n",
    "    trial_output_field='output',\n",
    "    trial_heat_onset_field='laseron',\n",
    "    trial_turn_field='turn_frame',\n",
    "    trial_fr=160\n",
    ")\n",
    "F201.set_image_metadata(\n",
    "    image='results/F201_imfinfo_edit.mat',\n",
    "    image_var='image',\n",
    "    image_time_field='ImageDescription',\n",
    "    image_fr=4.5\n",
    ")\n",
    "F201.set_component_evaluation(snr_thr=1.25, baseline_name='baseline', baseline_selected=1)\n",
    "F201.set_alignment_params(max_seconds_turn_to_end=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077533f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently selected hyperparameters\n",
    "hyp = F147"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a877f2e",
   "metadata": {},
   "source": [
    "## Metadata Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the main project directory\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccaab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trial and image metadata\n",
    "trial_info = sio.loadmat(hyp.trial)[hyp.trial_var].flatten()\n",
    "image_info = sio.loadmat(hyp.image)[hyp.image_var].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f5640",
   "metadata": {},
   "source": [
    "## Trial Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the fields containing time information in the trial metadata\n",
    "trial_time_index = trial_info.dtype.names.index(hyp.trial_time_field)\n",
    "\n",
    "# Get the indices of the fields containing time information in the image metadata\n",
    "image_time_index = image_info.dtype.names.index(hyp.image_time_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f483f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store the trial that each frame belongs to\n",
    "trials_by_frame = np.empty(image_info.size)\n",
    "\n",
    "# Initialize an array to store the number of frames for each trial\n",
    "frames_per_trial = np.zeros(trial_info.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to hold start and end time data for each trial\n",
    "trial_times_start = np.empty(trial_info.size, dtype='datetime64[us]')\n",
    "trial_times_end = np.empty(trial_info.size, dtype='datetime64[us]')\n",
    "\n",
    "# Initialize an array to hold the time data for each frame\n",
    "frame_timestamps = np.empty(image_info.size, dtype='datetime64[us]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf337160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the start and end time of each trial\n",
    "for i in range(trial_info.size):\n",
    "    trial_times_start[i] = timestamp_to_datetime(trial_info[i][trial_time_index][0])\n",
    "    trial_times_end[i] = timestamp_to_datetime(trial_info[i][trial_time_index][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trial grouping parameters\n",
    "trial_curr = 0\n",
    "image_curr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which trial each frame belongs to\n",
    "while image_curr < image_info.size:\n",
    "    \n",
    "    # Record the time of the current frame\n",
    "    image_time = image_desc_to_datetime(image_info[image_curr][image_time_index][0])\n",
    "    frame_timestamps[image_curr] = image_time\n",
    "    \n",
    "    # Check if the time of the current frame is before the start time of the current trial\n",
    "    if image_time < trial_times_start[trial_curr]:\n",
    "        \n",
    "        # The current frame does not belong to any trial\n",
    "        trials_by_frame[image_curr] = np.nan\n",
    "        \n",
    "        # Move on to the next frame\n",
    "        image_curr += 1\n",
    "    \n",
    "    # Check if the time of the current frame is after the end time of the current trial\n",
    "    elif image_time > trial_times_end[trial_curr]:\n",
    "        \n",
    "        # Move on to the next trial if there are still trials remaining\n",
    "        if trial_curr < trial_info.size - 1:\n",
    "            trial_curr += 1\n",
    "        \n",
    "        # The current frame is past the end time of the last trial otherwise\n",
    "        else:\n",
    "            \n",
    "            # Therefore, the current frame does not belong to any trial\n",
    "            trials_by_frame[image_curr] = np.nan\n",
    "            \n",
    "            # Move on to the next frame\n",
    "            image_curr += 1\n",
    "    \n",
    "    # The time of the current frame is within the time of the current trial otherwise\n",
    "    else:\n",
    "        \n",
    "        # Record the trial this frame belongs to\n",
    "        trials_by_frame[image_curr] = trial_curr\n",
    "        \n",
    "        # Update the number of frames contained in the current trial\n",
    "        frames_per_trial[trial_curr] += 1\n",
    "        \n",
    "        # Move on to the next frame\n",
    "        image_curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894505f6",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f058a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files containing results\n",
    "cnms = []\n",
    "for fname in hyp.estimates:\n",
    "    cnms.append(cnmf.load_CNMF(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the neural activity traces\n",
    "traces = []\n",
    "for cnm in cnms:\n",
    "    traces.append(cnm.estimates.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e009661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all traces\n",
    "data_orig = np.concatenate(traces, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3abd4",
   "metadata": {},
   "source": [
    "## Component Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the field in the trial metadata containing output\n",
    "trial_output_index = trial_info.dtype.names.index(hyp.trial_output_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all trials that are baselines\n",
    "baselines = []\n",
    "for i in range(trial_info.size):\n",
    "    if trial_info[i][trial_output_index][0] == hyp.baseline_name:\n",
    "        baselines.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb5ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the selected baseline as the noise region, calculate the standard deviation of the signal region\n",
    "std_sig = np.std(data_orig[:, np.where(trials_by_frame != baselines[hyp.baseline_selected])].squeeze(), axis=1, ddof=1)\n",
    "\n",
    "# Using the selected baseline as the noise region, calculate the standard deviation of the noise region\n",
    "std_noise = np.std(data_orig[:, np.where(trials_by_frame == baselines[hyp.baseline_selected])].squeeze(), axis=1, ddof=1)\n",
    "\n",
    "# Calculate the signal-to-noise ratio for each component\n",
    "sig_noise_ratio = std_sig / std_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify components as noise if their signal-to-noise ratios are below the threshold\n",
    "noise_indices = []\n",
    "for i in range(len(sig_noise_ratio)):\n",
    "    if sig_noise_ratio[i] < hyp.snr_thr:\n",
    "        noise_indices.append(i)\n",
    "\n",
    "# Remove all noise components\n",
    "data = np.delete(data_orig, noise_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa822e5",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d67212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store normalized data\n",
    "data_norm = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfdfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization\n",
    "data_norm['Z-Score'] = stats.zscore(data, axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization\n",
    "data_norm['Min-Max'] = min_max(data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74728c96",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default figure size\n",
    "sns.set_theme(rc={'figure.figsize': (17, 8.5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873dc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmaps for each method of normalization\n",
    "for method in data_norm:\n",
    "    sns.heatmap(data_norm[method], cmap='jet')\n",
    "    \n",
    "    # Add a title and labels to the heatmap\n",
    "    plt.title(\"Extracted Sources Normalized Using \" + method)\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"Source\")\n",
    "    \n",
    "    # Display the final heatmap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38dde48",
   "metadata": {},
   "source": [
    "## Time Series Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty arrays to hold the heat onset and initial turn times\n",
    "heat_onset = np.empty(trial_info.size, dtype='datetime64[us]')\n",
    "initial_turn = np.empty(trial_info.size, dtype='datetime64[us]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the fields in the trial metadata containing information on heat onset and turns\n",
    "heat_onset_index = trial_info.dtype.names.index(hyp.trial_heat_onset_field)\n",
    "turn_index = trial_info.dtype.names.index(hyp.trial_turn_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the heat onset and first turn times for each trial\n",
    "for i in range(trial_info.size):\n",
    "    \n",
    "    # Convert the frame of the heat onset into a time and save it\n",
    "    heat_onset_frame = trial_info[i][heat_onset_index][0, 0]\n",
    "    heat_onset[i] = add_frames_to_datetime(trial_times_start[i], heat_onset_frame, hyp.trial_fr)\n",
    "    \n",
    "    # Get all frames of turns\n",
    "    turn_frames = trial_info[i][turn_index][0]\n",
    "    \n",
    "    # Do not save a time if there are no turns\n",
    "    if turn_frames.size == 0:\n",
    "        initial_turn[i] = np.datetime64('NaT')\n",
    "    \n",
    "    # Save the time of the first frame with a turn otherwise\n",
    "    else:\n",
    "        initial_turn[i] = add_frames_to_datetime(trial_times_start[i], turn_frames[0], hyp.trial_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the time and frame number of all frames between the start and heat onset of each trial\n",
    "start_to_heat = defaultdict(dict)\n",
    "\n",
    "# Create a dictionary to store the time and frame number of all frames between the heat onset and first turn of each trial\n",
    "heat_to_turn = defaultdict(dict)\n",
    "\n",
    "# Create a dictionary to store the time and frame number of all frames between the first turn and end of each trial\n",
    "turn_to_end = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695078a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store trials to be kept\n",
    "valid_trials = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add frame and time information to the dictionaries\n",
    "for trial in range(trial_info.size):\n",
    "    \n",
    "    # Do not keep baselines or trials where no turns occurred\n",
    "    if trial in baselines or np.isnat(initial_turn[trial]):\n",
    "        continue\n",
    "    \n",
    "    # Add the trial number to the list of valid trials\n",
    "    valid_trials.append(trial)\n",
    "    \n",
    "    # Determine which time interval each frame in the current trial belongs to\n",
    "    for frame in np.where(trials_by_frame == trial)[0]:\n",
    "        \n",
    "        # The frame is between the start and heat onset if its time is before the heat onset time\n",
    "        if frame_timestamps[frame] < heat_onset[trial]:\n",
    "            start_to_heat[trial][frame] = frame_timestamps[frame]\n",
    "        \n",
    "        # Otherwise, the frame is between the heat onset and first turn if its time is before the first turn time\n",
    "        elif frame_timestamps[frame] < initial_turn[trial]:\n",
    "            heat_to_turn[trial][frame] = frame_timestamps[frame]\n",
    "        \n",
    "        # Otherwise, the frame is between the first turn and end\n",
    "        else:\n",
    "            turn_to_end[trial][frame] = frame_timestamps[frame]\n",
    "    \n",
    "    \n",
    "    ########## HEURISTIC CODE - ASK AT MEETING\n",
    "    ########## HEURISTIC CODE - ASK AT MEETING\n",
    "    ########## HEURISTIC CODE - ASK AT MEETING\n",
    "    ########## HEURISTIC CODE - ASK AT MEETING\n",
    "    ########## HEURISTIC CODE - ASK AT MEETING\n",
    "    if len(heat_to_turn[trial]) == 0:\n",
    "        valid_trials.remove(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values to determine how many frames to use for each time interval\n",
    "n_frames_start_to_heat = 0\n",
    "n_frames_heat_to_turn = 0\n",
    "n_frames_turn_to_end = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be91ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average number of frames between the start and heat onset of each trial\n",
    "for trial in valid_trials:\n",
    "    n_frames_start_to_heat += len(start_to_heat[trial])\n",
    "n_frames_start_to_heat = round(n_frames_start_to_heat / len(valid_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91986127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average number of frames between the heat onset and first turn of each trial\n",
    "for trial in valid_trials:\n",
    "    n_frames_heat_to_turn += len(heat_to_turn[trial])\n",
    "n_frames_heat_to_turn = round(n_frames_heat_to_turn / len(valid_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum number of frames between the first turn and end of each trial\n",
    "for trial in valid_trials:\n",
    "    n_frames_turn_to_end = min(n_frames_turn_to_end, len(turn_to_end[trial]))\n",
    "\n",
    "# Place an upper bound on the minimum\n",
    "n_frames_turn_to_end = min(n_frames_turn_to_end, round(hyp.max_seconds_turn_to_end * hyp.image_fr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69d101",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2936d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty tensors to store interpolated time series for each time interval\n",
    "interpol_start_to_heat = np.empty((len(valid_trials), data.shape[0], n_frames_start_to_heat))\n",
    "interpol_heat_to_turn = np.empty((len(valid_trials), data.shape[0], n_frames_heat_to_turn))\n",
    "interpol_turn_to_end = np.empty((len(valid_trials), data.shape[0], n_frames_turn_to_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7fc61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interpolate points from trial start times to heat onset times\n",
    "for i, trial in enumerate(valid_trials):\n",
    "    \n",
    "    # Find the start and end times of this interval using the first and last frames\n",
    "    frame_start = min(start_to_heat[trial])\n",
    "    frame_end = max(start_to_heat[trial])\n",
    "    time_start = start_to_heat[trial][frame_start]\n",
    "    time_end = start_to_heat[trial][frame_end]\n",
    "    \n",
    "    # Find the smallest time interval needed to separate the total time into n_frames_start_to_heat sections\n",
    "    time_unit = (time_end - time_start) / (n_frames_start_to_heat - 1)\n",
    "    \n",
    "    # Separate the interval and find frame numbers needed for interpolation\n",
    "    times_interpol = np.arange(time_start, time_end, time_unit)\n",
    "    frames_interpol = datetime_to_frame(times_interpol, time_start, frame_start, hyp.image_fr)\n",
    "    \n",
    "    # Create a function to interpolate the time series\n",
    "    x = np.array(list(start_to_heat[trial].keys()))\n",
    "    y = data[:, x]\n",
    "    f = interpolate.interp1d(x, y, axis=1)\n",
    "    \n",
    "    # Save the interpolated values\n",
    "    interpol_start_to_heat[i] = f(frames_interpol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate points from heat onset times to initial turn times\n",
    "for i, trial in enumerate(valid_trials):\n",
    "    \n",
    "    # Find the start and end times of this interval using the first and last frames\n",
    "    frame_start = min(heat_to_turn[trial])\n",
    "    frame_end = max(heat_to_turn[trial])\n",
    "    time_start = heat_to_turn[trial][frame_start]\n",
    "    time_end = heat_to_turn[trial][frame_end]\n",
    "    \n",
    "    # Find the smallest time interval needed to separate the total time into n_frames_heat_to_turn sections\n",
    "    time_unit = (time_end - time_start) / (n_frames_heat_to_turn - 1)\n",
    "    \n",
    "    # Separate the interval and find frame numbers needed for interpolation\n",
    "    times_interpol = np.arange(time_start, time_end, time_unit)\n",
    "    frames_interpol = datetime_to_frame(times_interpol, time_start, frame_start, hyp.image_fr)\n",
    "    \n",
    "    # Create a function to interpolate the time series\n",
    "    x = np.array(list(heat_to_turn[trial].keys()))\n",
    "    y = data[:, x]\n",
    "    f = interpolate.interp1d(x, y, axis=1)\n",
    "    \n",
    "    # Save the interpolated values\n",
    "    interpol_heat_to_turn[i] = f(frames_interpol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find only the first n_frames_turn_to_end frames for initial turn times to trial end times\n",
    "for i, trial in enumerate(valid_trials):\n",
    "    frames_keep = np.array(list(turn_to_end[trial].keys())[:n_frames_turn_to_end])\n",
    "    \n",
    "    # Save the first n_frames_turn_to_end frames\n",
    "    interpol_turn_to_end[i] = data[:, frames_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ba824",
   "metadata": {},
   "source": [
    "## Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the interpolation results into a tensor\n",
    "tensor = np.concatenate((interpol_start_to_heat, interpol_heat_to_turn, interpol_turn_to_end), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d67bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tensor shape information\n",
    "trials, neurons, times = tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04440c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization\n",
    "tensor_norm = np.reshape(min_max(np.reshape(tensor, (neurons, times * trials)), axis=1), (trials, neurons, times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b907bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the normalized tensor\n",
    "np.save('results/' + hyp.name + '_tensor.npy', tensor_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
