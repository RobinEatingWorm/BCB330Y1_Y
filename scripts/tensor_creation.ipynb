{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349cdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caiman.source_extraction.cnmf import cnmf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import os\n",
    "\n",
    "from src.datetime import add_frames_to_datetime, image_desc_to_datetime, timestamp_to_datetime\n",
    "from src.interpolate import interpolate, stitch, truncate\n",
    "from src.tensor import minmax\n",
    "from src.tensor_creation_hyperparams import Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fe93d",
   "metadata": {},
   "source": [
    "## Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4957601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for F147\n",
    "F147 = Hyperparams(name='F147')\n",
    "F147.set_data_paths(estimates=[\n",
    "    'results/F147_0_memmap__d1_247_d2_256_d3_1_order_C_frames_20995_.hdf5',\n",
    "    'results/F147_1_memmap__d1_73_d2_256_d3_1_order_C_frames_20995_.hdf5'\n",
    "])\n",
    "F147.set_trial_metadata(\n",
    "    trial='data/2p_raw/F147/20210526_LT_18_0.mat',\n",
    "    trial_var='trial',\n",
    "    trial_time_field='timestamps',\n",
    "    trial_output_field='output',\n",
    "    trial_fr=160\n",
    ")\n",
    "F147.set_image_metadata(\n",
    "    image='results/F147_imfinfo_edit.mat',\n",
    "    image_var='image',\n",
    "    image_time_field='ImageDescription',\n",
    "    image_fr=4.5\n",
    ")\n",
    "F147.set_component_evaluation(snr_thr=1.25, baseline_name='baseline', baseline_selected=1)\n",
    "F147.set_visualization_params(n_clusters=20, heatmap_bound=2)\n",
    "F147.set_alignment_params(\n",
    "    events_field = ['laseron', 'turn_frame', 'laseroff'],\n",
    "    align_opts = [('interpolate', 'mean'), ('interpolate', 'mean'), ('stitch', [2, 2]), ('truncate', 20)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for F201\n",
    "F201 = Hyperparams(name='F201')\n",
    "F201.set_data_paths(estimates=[\n",
    "    'results/F201_0_memmap__d1_320_d2_256_d3_1_order_C_frames_24040_.hdf5'\n",
    "])\n",
    "F201.set_trial_metadata(\n",
    "    trial='data/2p_raw/F201/20210812_RT_13_59.mat',\n",
    "    trial_var='trial',\n",
    "    trial_time_field='timestamps',\n",
    "    trial_output_field='output',\n",
    "    trial_fr=160\n",
    ")\n",
    "F201.set_image_metadata(\n",
    "    image='results/F201_imfinfo_edit.mat',\n",
    "    image_var='image',\n",
    "    image_time_field='ImageDescription',\n",
    "    image_fr=4.5\n",
    ")\n",
    "F201.set_component_evaluation(snr_thr=1.25, baseline_name='baseline', baseline_selected=1)\n",
    "F201.set_visualization_params(n_clusters=20, heatmap_bound=2)\n",
    "F201.set_alignment_params(\n",
    "    events_field = ['laseron', 'turn_frame', 'laseroff'],\n",
    "    align_opts = [('interpolate', 'mean'), ('interpolate', 'mean'), ('stitch', [2, 2]), ('truncate', 20)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077533f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently selected hyperparameters\n",
    "hyp = F147"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a877f2e",
   "metadata": {},
   "source": [
    "## Metadata Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the main project directory\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccaab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trial and image metadata\n",
    "trial_info = sio.loadmat(hyp.trial)[hyp.trial_var].flatten()\n",
    "image_info = sio.loadmat(hyp.image)[hyp.image_var].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f5640",
   "metadata": {},
   "source": [
    "## Trial Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the fields containing time information in the trial metadata\n",
    "trial_time_index = trial_info.dtype.names.index(hyp.trial_time_field)\n",
    "\n",
    "# Get the indices of the fields containing time information in the image metadata\n",
    "image_time_index = image_info.dtype.names.index(hyp.image_time_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f483f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store the trial that each frame belongs to\n",
    "trials_by_frame = np.empty(image_info.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to hold start and end time data for each trial\n",
    "trial_times_start = np.empty(trial_info.size, dtype='datetime64[us]')\n",
    "trial_times_end = np.empty(trial_info.size, dtype='datetime64[us]')\n",
    "\n",
    "# Initialize an array to hold the time data for each frame\n",
    "frame_timestamps = np.empty(image_info.size, dtype='datetime64[us]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf337160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the start and end time of each trial\n",
    "for i in range(trial_info.size):\n",
    "    trial_times_start[i] = timestamp_to_datetime(trial_info[i][trial_time_index][0])\n",
    "    trial_times_end[i] = timestamp_to_datetime(trial_info[i][trial_time_index][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trial grouping parameters\n",
    "trial_curr = 0\n",
    "image_curr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which trial each frame belongs to\n",
    "while image_curr < image_info.size:\n",
    "    \n",
    "    # Record the time of the current frame\n",
    "    image_time = image_desc_to_datetime(image_info[image_curr][image_time_index][0])\n",
    "    frame_timestamps[image_curr] = image_time\n",
    "    \n",
    "    # Check if the time of the current frame is before the start time of the current trial\n",
    "    if image_time < trial_times_start[trial_curr]:\n",
    "        \n",
    "        # The current frame does not belong to any trial\n",
    "        trials_by_frame[image_curr] = np.nan\n",
    "        \n",
    "        # Move on to the next frame\n",
    "        image_curr += 1\n",
    "    \n",
    "    # Check if the time of the current frame is after the end time of the current trial\n",
    "    elif image_time > trial_times_end[trial_curr]:\n",
    "        \n",
    "        # Move on to the next trial if there are still trials remaining\n",
    "        if trial_curr < trial_info.size - 1:\n",
    "            trial_curr += 1\n",
    "        \n",
    "        # The current frame is past the end time of the last trial otherwise\n",
    "        else:\n",
    "            \n",
    "            # Therefore, the current frame does not belong to any trial\n",
    "            trials_by_frame[image_curr] = np.nan\n",
    "            \n",
    "            # Move on to the next frame\n",
    "            image_curr += 1\n",
    "    \n",
    "    # The time of the current frame is within the time of the current trial otherwise\n",
    "    else:\n",
    "        \n",
    "        # Record the trial this frame belongs to\n",
    "        trials_by_frame[image_curr] = trial_curr\n",
    "        \n",
    "        # Move on to the next frame\n",
    "        image_curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894505f6",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f058a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files containing results\n",
    "cnms = []\n",
    "for fname in hyp.estimates:\n",
    "    cnms.append(cnmf.load_CNMF(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the neural activity traces\n",
    "traces = []\n",
    "for cnm in cnms:\n",
    "    traces.append(cnm.estimates.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e009661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all traces\n",
    "data_orig = np.concatenate(traces, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3abd4",
   "metadata": {},
   "source": [
    "## Component Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the field in the trial metadata containing output\n",
    "trial_output_index = trial_info.dtype.names.index(hyp.trial_output_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all trials that are baselines\n",
    "trials_baseline = []\n",
    "for i in range(trial_info.size):\n",
    "    if trial_info[i][trial_output_index][0] == hyp.baseline_name:\n",
    "        trials_baseline.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb5ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the selected baseline as the noise region, calculate the standard deviation of the signal region\n",
    "std_sig = np.std(\n",
    "    data_orig[:, np.where(trials_by_frame != trials_baseline[hyp.baseline_selected])].squeeze(),\n",
    "    axis=1, ddof=1)\n",
    "\n",
    "# Using the selected baseline as the noise region, calculate the standard deviation of the noise region\n",
    "std_noise = np.std(\n",
    "    data_orig[:, np.where(trials_by_frame == trials_baseline[hyp.baseline_selected])].squeeze(),\n",
    "    axis=1, ddof=1)\n",
    "\n",
    "# Calculate the signal-to-noise ratio for each component\n",
    "sig_noise_ratio = std_sig / std_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify components as noise if their signal-to-noise ratios are below the threshold\n",
    "noise_indices = []\n",
    "for i in range(len(sig_noise_ratio)):\n",
    "    if sig_noise_ratio[i] < hyp.snr_thr:\n",
    "        noise_indices.append(i)\n",
    "\n",
    "# Remove all noise components\n",
    "data = np.delete(data_orig, noise_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3653b",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc893020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data by z-score\n",
    "data_norm = stats.zscore(data, axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213db3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data by clusters\n",
    "clustering = AgglomerativeClustering(n_clusters=hyp.n_clusters).fit_predict(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into clusters\n",
    "data_clusters = [[] for i in range(hyp.n_clusters)]\n",
    "for i in range(data_norm.shape[0]):\n",
    "    data_clusters[clustering[i]].append(data_norm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3850adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the clusters\n",
    "data_norm = np.concatenate(data_clusters, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74728c96",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default figure size\n",
    "sns.set_theme(rc={'figure.figsize': (6.5, 3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873dc5eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "sns.heatmap(data_norm, vmin=-hyp.heatmap_bound, vmax=hyp.heatmap_bound, cmap='jet')\n",
    "\n",
    "# Add a title and labels to the heatmap\n",
    "plt.title(hyp.name + \" Extracted Sources\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Source\")\n",
    "\n",
    "# Remove axis tick numbers\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Display the final heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a11d754",
   "metadata": {},
   "source": [
    "## Alignment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of events and number of intervals\n",
    "n_event = len(hyp.events_field)\n",
    "n_interval = len(hyp.align_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the fields in the trial metadata containing event frame information\n",
    "events_index = []\n",
    "for event_field in hyp.events_field:\n",
    "    events_index.append(trial_info.dtype.names.index(event_field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array to hold times of events used for alignment\n",
    "events_time = np.empty((len(hyp.events_field), trial_info.size), dtype='datetime64[us]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0651e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all event times\n",
    "for i in range(len(events_index)):\n",
    "    \n",
    "    # Find the time of the current event for each trial\n",
    "    for trial in range(trial_info.size):\n",
    "        \n",
    "        # Get an array of event frames\n",
    "        event_frames = trial_info[trial][events_index[i]][0]\n",
    "        \n",
    "        # Do not save a time if the event did not occur\n",
    "        if event_frames.size == 0:\n",
    "            events_time[i, trial] = np.datetime64('NaT')\n",
    "        \n",
    "        # Save the first time in the array otherwise\n",
    "        else:\n",
    "            events_time[i, trial] = add_frames_to_datetime(trial_times_start[trial], event_frames[0], hyp.trial_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty arrays to hold the first and last frames of each interval\n",
    "intervals_frame_first = np.full((len(hyp.events_field) + 1, trial_info.size), np.nan)\n",
    "intervals_frame_last = np.full((len(hyp.events_field) + 1, trial_info.size), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0259bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store trials to be kept and trials to be replaced\n",
    "trials_valid = []\n",
    "trials_replace = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2788ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add interval frame bounds and trial validity information\n",
    "for trial in range(trial_info.size):\n",
    "    \n",
    "    # Do not keep baselines\n",
    "    if trial in trials_baseline:\n",
    "        continue\n",
    "    \n",
    "    # If any event is missing, replace the trial with the last valid trial\n",
    "    if np.sum(np.isnat(events_time[:, trial])) > 0:\n",
    "        trials_replace.append(trial)\n",
    "        continue\n",
    "    \n",
    "    # Determine the first and last frames of each interval\n",
    "    for frame in np.where(trials_by_frame == trial)[0]:\n",
    "        \n",
    "        # Boolean for determining if the frame belongs to the interval after the last event\n",
    "        in_last_interval = True\n",
    "        \n",
    "        # Determine which interval the frame belongs to\n",
    "        for i in range(events_time.shape[0]):\n",
    "            \n",
    "            # The frame is in the interval before the event if its time is before the event time\n",
    "            if frame_timestamps[frame] < events_time[i, trial]:\n",
    "                \n",
    "                # Set the frame as the first one of the interval if none exists\n",
    "                if np.isnan(intervals_frame_first[i, trial]):\n",
    "                    intervals_frame_first[i, trial] = frame\n",
    "                \n",
    "                # Update the last frame of the interval\n",
    "                intervals_frame_last[i, trial] = frame\n",
    "                \n",
    "                # The frame cannot belong to any other intervals, so do not check the rest\n",
    "                in_last_interval = False\n",
    "                break\n",
    "        \n",
    "        # If the frame occurs after all events, it is part of the last interval\n",
    "        if in_last_interval:\n",
    "            \n",
    "            # Set the frame as the first one of the last interval if none exists\n",
    "            if np.isnan(intervals_frame_first[-1, trial]):\n",
    "                intervals_frame_first[-1, trial] = frame\n",
    "                \n",
    "            # Update the last frame of the last interval\n",
    "            intervals_frame_last[-1, trial] = frame \n",
    "    \n",
    "    # Replace the trial if any interval does not contain frames\n",
    "    if np.sum(np.isnan(intervals_frame_first[:, trial])) > 0:\n",
    "        trials_replace.append(trial)\n",
    "    \n",
    "    # The trial is valid otherwise\n",
    "    else:\n",
    "        trials_valid.append(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the number of frames needed for each interval\n",
    "intervals_n = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31efabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and minimum number of frames for each interval\n",
    "intervals_frame_elapsed = intervals_frame_last[:, trials_valid] - intervals_frame_first[:, trials_valid] + 1\n",
    "intervals_frame_elapsed_mean = np.mean(intervals_frame_elapsed, axis=1).astype(np.int64)\n",
    "intervals_frame_elapsed_min = np.min(intervals_frame_elapsed, axis=1).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of frames needed for each interval\n",
    "for i in range(len(hyp.align_opts)):\n",
    "    \n",
    "    # For regular interpolation, use the mean or specified number of seconds\n",
    "    if hyp.align_opts[i][0] == 'interpolate':\n",
    "        if hyp.align_opts[i][1] == 'mean':\n",
    "            intervals_n.append(intervals_frame_elapsed_mean[i])\n",
    "        else:\n",
    "            intervals_n.append(round(hyp.align_opts[i][1] * hyp.image_fr))\n",
    "    \n",
    "    # For stitching, use the total specified number of seconds\n",
    "    elif hyp.align_opts[i][0] == 'stitch':\n",
    "        intervals_n.append(round(hyp.align_opts[i][1][0] * hyp.image_fr) + \n",
    "                           round(hyp.align_opts[i][1][1] * hyp.image_fr))\n",
    "    \n",
    "    # For truncating, use the minimum, possible bounded above by the specified number of seconds\n",
    "    elif hyp.align_opts[i][0] == 'truncate':\n",
    "        if hyp.align_opts[i][1] == 'min':\n",
    "            intervals_n.append(intervals_frame_elapsed_min[i])\n",
    "        else:\n",
    "            intervals_n.append(min(intervals_frame_elapsed_min[i], round(hyp.align_opts[i][1] * hyp.image_fr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of frames per interval and cumulative number of frames\n",
    "cumulative = 0\n",
    "for interval_n in intervals_n:\n",
    "    cumulative += interval_n\n",
    "    print(interval_n, cumulative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934e31c",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce35c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all trials performed in the experiment in order\n",
    "trials_experiment = sorted(trials_valid + trials_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88076bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty tensors to store interpolated time series for each interval\n",
    "interpol = []\n",
    "for interval_n in intervals_n:\n",
    "    interpol.append(np.empty((len(trials_experiment), data_norm.shape[0], interval_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d96058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Interpolate points for each trial\n",
    "for i, trial in enumerate(trials_experiment):\n",
    "    \n",
    "    # Interpolate points if the trial is valid\n",
    "    if trial in trials_valid:\n",
    "        \n",
    "        # Initialize an array to hold distances for translating the data after stitching\n",
    "        distance = np.zeros((data_norm.shape[0], 1))\n",
    "    \n",
    "        # Interpolate points within each interval of the current trial\n",
    "        for j in range(len(hyp.align_opts)):\n",
    "            \n",
    "            # Get the indices and times of the first and last image frame in the interval\n",
    "            frame_start = int(intervals_frame_first[j, trial])\n",
    "            frame_end = int(intervals_frame_last[j, trial])\n",
    "            time_start = frame_timestamps[frame_start]\n",
    "            time_end = frame_timestamps[frame_end]\n",
    "            \n",
    "            # Interpolate data within the interval if specified\n",
    "            if hyp.align_opts[j][0] == 'interpolate':\n",
    "                interpol[j][i] = interpolate(data_norm, intervals_n[j], time_start, time_end,\n",
    "                                                    frame_start, frame_end, hyp.image_fr)\n",
    "                interpol[j][i] += distance\n",
    "            \n",
    "            # Check if stitching is specified\n",
    "            elif hyp.align_opts[j][0] == 'stitch':\n",
    "                \n",
    "                # If there is not enough frames to stitch, interpolate data instead\n",
    "                if frame_end - frame_start + 1 < intervals_n[j]:\n",
    "                    interpol[j][i] = interpolate(data_norm, intervals_n[j], time_start, time_end,\n",
    "                                                        frame_start, frame_end, hyp.image_fr)\n",
    "                    interpol[j][i] += distance\n",
    "                \n",
    "                # Stitch the start and end of the interval together otherwise and update the translation distance\n",
    "                else:\n",
    "                    interpol[j][i], distance_change = stitch(data_norm, hyp.align_opts[j][1],\n",
    "                                                            frame_start, frame_end, hyp.image_fr)\n",
    "                    interpol[j][i] += distance\n",
    "                    distance += distance_change\n",
    "            \n",
    "            # Truncate data in the interval if speified\n",
    "            elif hyp.align_opts[j][0] == 'truncate':\n",
    "                interpol[j][i] = truncate(data_norm, intervals_n[j], frame_start)\n",
    "                interpol[j][i] += distance\n",
    "        \n",
    "    # Use the previous trial's interpolated data if the trial needs to be replaced (assuming the first trial is valid)\n",
    "    else:\n",
    "        for j in range(len(hyp.align_opts)):\n",
    "            interpol[j][i] = interpol[j][i - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f647e3b",
   "metadata": {},
   "source": [
    "## Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the interpolation results into a tensor\n",
    "tensor = np.concatenate(interpol, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c90c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tensor shape information\n",
    "trials, neurons, times = tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create an array used as a two-dimensional version of the tensor (debug, problems arise with np.reshape)\n",
    "tensor_2d = np.empty((neurons, times * trials))\n",
    "for i in range(trials):\n",
    "    tensor_2d[:, i * times:(i + 1) * times] = tensor[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "sns.heatmap(tensor_2d, vmin=-hyp.heatmap_bound, vmax=hyp.heatmap_bound, cmap='jet')\n",
    "\n",
    "# Add a title and labels to the heatmap\n",
    "plt.title(hyp.name + \" Extracted Sources After Alignment\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Source\")\n",
    "\n",
    "# Remove axis tick numbers\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Display the final heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization\n",
    "tensor_minmax_2d = minmax(tensor_2d, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd4033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create a three-dimensional tensor using the min-max array\n",
    "tensor_minmax = np.empty((trials, neurons, times))\n",
    "for i in range(trials):\n",
    "    tensor_minmax[i] = tensor_minmax_2d[:, i * times:(i + 1) * times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the two tensors\n",
    "np.save('results/' + hyp.name + '_tensor_zscore.npy', tensor)\n",
    "np.save('results/' + hyp.name + '_tensor_minmax.npy', tensor_minmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
